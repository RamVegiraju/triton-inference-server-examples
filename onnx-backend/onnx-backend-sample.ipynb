{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c44f65-f2f4-439a-8cdc-b1cca65c19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a51ce57-81f2-4caf-94f2-ec8032a03a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/msmarco-bert-base-dot-v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c34a923-1e53-4423-8849-c6c3ca720185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "query = \"How many people live in London?\"\n",
    "encoded_input = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "#print(encoded_input)\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input, return_dict=True)\n",
    "    #print(model_output)\n",
    "# Perform pooling\n",
    "embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "#print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b561120-2369-44c6-8641-5506a89eca80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers.onnx import FeaturesManager\n",
    "from pathlib import Path\n",
    "\n",
    "# load config\n",
    "model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model)\n",
    "onnx_config = model_onnx_config(model.config)\n",
    "\n",
    "# export\n",
    "onnx_inputs, onnx_outputs = transformers.onnx.export(\n",
    "        preprocessor=tokenizer,\n",
    "        model=model,\n",
    "        config=onnx_config,\n",
    "        opset=13,\n",
    "        output=Path(\"model.onnx\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cdbbc8-d7ff-49bf-a8fb-8f4833eb570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7f3d7-a7b3-48ac-ab23-a867247efb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cb92f-4fad-4d3d-99bb-4a21526d4534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f850475-4711-4fd1-adee-f74d5660dca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2d061-2ff9-455b-9231-fa97e016173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
